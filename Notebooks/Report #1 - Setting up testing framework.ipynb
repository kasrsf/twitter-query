{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from CustomTransformers import *\n",
    "from Evaluation import *\n",
    "from FeatureExtraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../data/training.json\")\n",
    "test = pd.read_json(\"../data/test.json\")\n",
    "\n",
    "train_features = train.drop('label', axis=1)\n",
    "train_target = train['label']\n",
    "\n",
    "test_features = test.drop('label', axis=1)\n",
    "test_target = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_time</th>\n",
       "      <th>from_id</th>\n",
       "      <th>from_user</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>label</th>\n",
       "      <th>location</th>\n",
       "      <th>mention</th>\n",
       "      <th>term</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-10-07 17:46:10</td>\n",
       "      <td>1042956938</td>\n",
       "      <td>_kayxchi</td>\n",
       "      <td>empty_hashtag</td>\n",
       "      <td>0</td>\n",
       "      <td>empty_location</td>\n",
       "      <td>TheRealKhaa__</td>\n",
       "      <td>my hair not messed up but this umbrella keep b...</td>\n",
       "      <td>387212256515469312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-07-13 02:16:11</td>\n",
       "      <td>340590272</td>\n",
       "      <td>HighImCoreyy</td>\n",
       "      <td>empty_hashtag</td>\n",
       "      <td>0</td>\n",
       "      <td>empty_location</td>\n",
       "      <td>trentxsweat</td>\n",
       "      <td>wtf you ass</td>\n",
       "      <td>355812862075224064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-06-08 10:49:18</td>\n",
       "      <td>1576430503</td>\n",
       "      <td>emiliee171</td>\n",
       "      <td>empty_hashtag</td>\n",
       "      <td>0</td>\n",
       "      <td>empty_location</td>\n",
       "      <td>FIirtationship</td>\n",
       "      <td>rt if i get mad at you that means i still care...</td>\n",
       "      <td>475529987781447680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2014-01-06 02:27:00</td>\n",
       "      <td>2270482320</td>\n",
       "      <td>TodoSismos</td>\n",
       "      <td>Earthquake Sismo</td>\n",
       "      <td>1</td>\n",
       "      <td>loc_argentina</td>\n",
       "      <td>empty_mention</td>\n",
       "      <td>m 10 6km nw of the geysers california time2014...</td>\n",
       "      <td>419943136907898880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2014-01-21 06:00:32</td>\n",
       "      <td>377627543</td>\n",
       "      <td>_heyitsmadison_</td>\n",
       "      <td>empty_hashtag</td>\n",
       "      <td>0</td>\n",
       "      <td>loc_city_of_brotherly_love</td>\n",
       "      <td>comedyandtruth</td>\n",
       "      <td>when a girl says im fine</td>\n",
       "      <td>425432692306350080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             create_time     from_id        from_user           hashtag  \\\n",
       "0    2013-10-07 17:46:10  1042956938         _kayxchi     empty_hashtag   \n",
       "1    2013-07-13 02:16:11   340590272     HighImCoreyy     empty_hashtag   \n",
       "10   2014-06-08 10:49:18  1576430503       emiliee171     empty_hashtag   \n",
       "100  2014-01-06 02:27:00  2270482320       TodoSismos  Earthquake Sismo   \n",
       "1000 2014-01-21 06:00:32   377627543  _heyitsmadison_     empty_hashtag   \n",
       "\n",
       "      label                    location         mention  \\\n",
       "0         0              empty_location   TheRealKhaa__   \n",
       "1         0              empty_location     trentxsweat   \n",
       "10        0              empty_location  FIirtationship   \n",
       "100       1               loc_argentina   empty_mention   \n",
       "1000      0  loc_city_of_brotherly_love  comedyandtruth   \n",
       "\n",
       "                                                   term            tweet_id  \n",
       "0     my hair not messed up but this umbrella keep b...  387212256515469312  \n",
       "1                                           wtf you ass  355812862075224064  \n",
       "10    rt if i get mad at you that means i still care...  475529987781447680  \n",
       "100   m 10 6km nw of the geysers california time2014...  419943136907898880  \n",
       "1000                           when a girl says im fine  425432692306350080  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Set up a pipeline for training a classifier based on the training data. Vectorize each of the five main feature columns (Term, Hashtag, From_id, Location, Mention) and create a single feature vector with FeatureUnion.\n",
    "The classifier is a Logistic Regression with Cross validation which currently is set up under the default configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion(\n",
    "            transformer_list=[\n",
    "                ('term', Pipeline([\n",
    "                    ('selector', ItemSelector(key='term')),\n",
    "                    ('tfidf', TfidfVectorizer()),\n",
    "                ])),\n",
    "                \n",
    "                ('hashtag', Pipeline([\n",
    "                    ('selector', ItemSelector(key='hashtag')),\n",
    "                    ('count', HashtagCountVectorizer()),\n",
    "                ])),\n",
    "                \n",
    "                ('user', Pipeline([\n",
    "                    ('selector', ItemSelector(key='from_user')),\n",
    "                    ('count', CountVectorizer()),\n",
    "                ])),\n",
    "                \n",
    "                ('location', Pipeline([\n",
    "                    ('selector', ItemSelector(key='location')),\n",
    "                    ('count', CountVectorizer()),\n",
    "                ])),\n",
    "                \n",
    "                ('mention', Pipeline([\n",
    "                    ('selector', ItemSelector(key='mention')),\n",
    "                    ('count', CountVectorizer()),\n",
    "                ]))\n",
    "               \n",
    "            ])),\n",
    "    \n",
    "    ('classifier', LogisticRegressionCV())\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train_features, train_target)\n",
    "\n",
    "predictions = pipeline.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@100 = 0.988636363636 \n",
      "Recall@100 = 0.956043956044\n",
      "AveP = 0.720796127248\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_summary(test_target, predictions, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('features', FeatureUnion(\n",
    "            transformer_list=[\n",
    "                ('term', Pipeline([\n",
    "                    ('selector', ItemSelector(key='term')),\n",
    "                    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "                ])),\n",
    "                \n",
    "                ('hashtag', Pipeline([\n",
    "                    ('selector', ItemSelector(key='hashtag')),\n",
    "                    ('count', HashtagCountVectorizer()),\n",
    "                ])),\n",
    "            ])),\n",
    "    \n",
    "    ('classifier', LogisticRegressionCV())    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline2.fit(train_features, train_target)\n",
    "\n",
    "predictions2 = pipeline2.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@100 = 1.0 \n",
      "Recall@100 = 1.0\n",
      "AveP = 0.890138539021\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_summary(test_target, predictions2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'#prayforthephilippines',\n",
       "  u'#earthquake',\n",
       "  u'#storm',\n",
       "  u'#tornado',\n",
       "  u'#ukstorm',\n",
       "  u'#haiyan',\n",
       "  u'#flood',\n",
       "  u'#sandy',\n",
       "  u'#hurricane',\n",
       "  u'#drought',\n",
       "  u'#arthur',\n",
       "  u'#eqnz',\n",
       "  u'#hurricanes',\n",
       "  u'#quake',\n",
       "  u'#typhoon',\n",
       "  u'#serbiafloods',\n",
       "  u'#napaquake',\n",
       "  u'#prayforchile',\n",
       "  u'#earthquakeph',\n",
       "  u'#tsunami',\n",
       "  u'#phailin',\n",
       "  u'#laearthquake',\n",
       "  u'#typhoonhaiyan',\n",
       "  u'#hurricanearthur',\n",
       "  u'#cholera',\n",
       "  u'#katrina',\n",
       "  u'#bertha',\n",
       "  u'#hurricanesandy',\n",
       "  u'#ukfloods',\n",
       "  u'#hurricanekatrina',\n",
       "  u'#napaearthquake',\n",
       "  u'#hurricanenation',\n",
       "  u'#manuel',\n",
       "  u'#laquake',\n",
       "  u'#quakecon2014',\n",
       "  u'#quakelive',\n",
       "  u'#quakecon',\n",
       "  u'#typhoonaid',\n",
       "  u'#tsunamimarch',\n",
       "  u'hurricane',\n",
       "  u'#hurricanekid',\n",
       "  u'#anc',\n",
       "  u'yrs',\n",
       "  u'#bosniafloods',\n",
       "  u'#typhoonyolanda',\n",
       "  u'#hurricaneseason',\n",
       "  u'#corkfloods',\n",
       "  u'#reddeer',\n",
       "  u'#abfloods',\n",
       "  u'#hurricaneprep',\n",
       "  u'help',\n",
       "  u'#kashmirfloods',\n",
       "  u'#re',\n",
       "  u'philippines',\n",
       "  u'safe',\n",
       "  u'eso',\n",
       "  u'#hurricanebertha',\n",
       "  u'storm',\n",
       "  u'#typhoonmaring',\n",
       "  u'#bayanihan',\n",
       "  u'#ascd14',\n",
       "  u'#hurricanenia',\n",
       "  u'#realworldportland',\n",
       "  u'#greenpeace',\n",
       "  u'typhoon',\n",
       "  u'weather',\n",
       "  u'#yolandaph',\n",
       "  u'#tracfone',\n",
       "  u'#philippines',\n",
       "  u'victims',\n",
       "  u'water',\n",
       "  u'#cityofnapa',\n",
       "  u'#india',\n",
       "  u'took',\n",
       "  u'in',\n",
       "  u'#hurricanefly',\n",
       "  u'#quevega',\n",
       "  u'#vautour',\n",
       "  u'#champagnefever',\n",
       "  u'#askbrody',\n",
       "  u'#nola',\n",
       "  u'#julio',\n",
       "  u'#njsandy',\n",
       "  u'forecast',\n",
       "  u'coast',\n",
       "  u'city',\n",
       "  u'of',\n",
       "  u'#unitedstates',\n",
       "  u'since',\n",
       "  u'#texas',\n",
       "  u'continue',\n",
       "  u'#bonjovi',\n",
       "  u'jfk',\n",
       "  u'damage',\n",
       "  u'#microsoftxbox',\n",
       "  u'#dasims',\n",
       "  u'place',\n",
       "  u'carnage',\n",
       "  u'ts',\n",
       "  u'risk'],\n",
       " [u'rlawler3',\n",
       "  u'shiftlessstevie',\n",
       "  u'thefoxnation01',\n",
       "  u'strangeaxle',\n",
       "  u'davidgumpher',\n",
       "  u'asifktkaziz',\n",
       "  u'earthquaketime1',\n",
       "  u'wfhcbandon',\n",
       "  u'905shinefm',\n",
       "  u'what_tha_what',\n",
       "  u'jrcommdoc',\n",
       "  u'nice_1005',\n",
       "  u'lawbharath',\n",
       "  u'psychkiddo',\n",
       "  u'suffolkdan86',\n",
       "  u'jilllaner',\n",
       "  u'gothjezebel',\n",
       "  u'millermarias',\n",
       "  u'butterflyblues4',\n",
       "  u'marnielevy',\n",
       "  u'ilovehim_o21',\n",
       "  u'gull_girl',\n",
       "  u'joshbrant',\n",
       "  u'gglasseducator',\n",
       "  u'kevinlynnclark',\n",
       "  u'martinb216',\n",
       "  u'typhoonnews',\n",
       "  u'sheethhashir',\n",
       "  u'pinnoock',\n",
       "  u'pindiscount',\n",
       "  u'donaldfrump',\n",
       "  u'disbronn04l1',\n",
       "  u'brianatwater',\n",
       "  u'deeedee07',\n",
       "  u'7deez',\n",
       "  u'mikeyrh1',\n",
       "  u'tommyricosuave',\n",
       "  u'gods_warrior8',\n",
       "  u'justinrubin',\n",
       "  u'srkzmessenger',\n",
       "  u'itrendnayan26',\n",
       "  u'quakenotices',\n",
       "  u'ericz_live',\n",
       "  u'stevepl303',\n",
       "  u'o_pottsi',\n",
       "  u'kwhalen12',\n",
       "  u'brianaaavargas',\n",
       "  u'henriettevisser',\n",
       "  u'hacktownnjpatch',\n",
       "  u'jeneng'],\n",
       " [u'loc_schuylkill_county_pa',\n",
       "  u'loc_los_angeles_ca',\n",
       "  u'loc_abu_dhabi_uae',\n",
       "  u'loc_bandon_co_cork',\n",
       "  u'loc_red_deer_ab',\n",
       "  u'loc_central_virginia',\n",
       "  u'loc_princeton',\n",
       "  u'loc_13',\n",
       "  u'loc_sta_mesa_manila_philippines',\n",
       "  u'loc_suffolk',\n",
       "  u'loc_chennai',\n",
       "  u'loc_paradise',\n",
       "  u'loc_seoulkorea',\n",
       "  u'loc_brighton',\n",
       "  u'loc_atlanta',\n",
       "  u'loc_nelson',\n",
       "  u'loc_las_vegas_nevada',\n",
       "  u'loc_wellington_new_zealand',\n",
       "  u'loc_santa_monica',\n",
       "  u'loc_west_virginia'],\n",
       " [u'clutchreed_25',\n",
       "  u'bethblog',\n",
       "  u'indiekings',\n",
       "  u'decappeal',\n",
       "  u'jonleebrody',\n",
       "  u'johnminihan',\n",
       "  u'fcc',\n",
       "  u'craigatfema',\n",
       "  u'sumansharma',\n",
       "  u'ypeer_phl',\n",
       "  u'gemmaduffy13',\n",
       "  u'nobts_live',\n",
       "  u'sofiaorden',\n",
       "  u'abscbnnews',\n",
       "  u'microbesinfect',\n",
       "  u'bernardokath',\n",
       "  u'fcbayern',\n",
       "  u'kennyhamilton',\n",
       "  u'tdmrussell',\n",
       "  u'davidsilveroak'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features_by_kind(pipeline, [100, 50, 20, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-2ad6bb2d770c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"all_feat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"terms+hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.05\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mlegend\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3795\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3797\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3798\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mlegend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_label'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(test_target, predictions)\n",
    "precision2, recall2, _ = precision_recall_curve(test_target, predictions2)\n",
    "\n",
    "plt.step(recall, precision, color='black', label=\"t\")\n",
    "plt.step(recall2, precision2, color='g', label=\"test\")\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(handles=[\"all_feat\", \"terms+hash\"])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
